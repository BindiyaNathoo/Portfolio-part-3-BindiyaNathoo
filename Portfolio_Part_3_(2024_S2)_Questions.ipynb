{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0ZKqZaTWkpg"
   },
   "source": [
    "# Portfolio Part 3 - Analysis of Loan Approval Data (2024 S2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9R7rVmlXaMX"
   },
   "source": [
    "## Task background\n",
    "In this Portfolio task, you will work on a new dataset named 'Loan Approval' which is a modified version from a synthetic Dataset for Risk Assessment and Loan Approval Modeling (many thanks to LORENZO ZOPPELLETTO for the sharing of this dataset). This dataset comprises 20,000 records of personal and financial data, designed to facilitate the development of predictive models for risk assessment and loan approval. In this portfolio part, you are mainly required to train classification models to determine the outcome of loan approval, indicating whether an applicant is likely to be approved or denied for a loan.\n",
    "\n",
    "The dataset includes diverse features such as demographic information, credit history, employment status, income levels, existing debt, and other relevant financial metrics, providing a comprehensive foundation for sophisticated data-driven analysis and decision-making.\n",
    "\n",
    "The dataset includes the following columns:\n",
    "\n",
    "|Column|Meaning|\n",
    "|:-----|:-----|\n",
    "|ApplicationDate| Loan application date|\n",
    "|Age| Applicant's age|\n",
    "|AnnualIncome| Yearly income|\n",
    "|CreditScore| Creditworthiness score|\n",
    "|EmploymentStatus| Job situation|\n",
    "|EducationLevel| Highest education attained|\n",
    "|Experience| Work experience|\n",
    "|LoanAmount| Requested loan size|\n",
    "|LoanDuration| Loan repayment period|\n",
    "|MaritalStatus| Applicant's marital state|\n",
    "|NumberOfDependents| Number of dependents|\n",
    "|HomeOwnershipStatus| Homeownership type|\n",
    "|MonthlyDebtPayments| Monthly debt obligations|\n",
    "|CreditCardUtilizationRate| Credit card usage percentage|\n",
    "|NumberOfOpenCreditLines| Active credit lines|\n",
    "|NumberOfCreditInquiries| Credit checks count|\n",
    "|DebtToIncomeRatio| Debt to income proportion|\n",
    "|BankruptcyHistory| Bankruptcy records|\n",
    "|LoanPurpose| Reason for loan|\n",
    "|PreviousLoanDefaults| Prior loan defaults|\n",
    "|PaymentHistory| Past payment behavior|\n",
    "|LengthOfCreditHistory| Credit history duration|\n",
    "|SavingsAccountBalance| Savings account amount|\n",
    "|CheckingAccountBalance| Checking account funds|\n",
    "|TotalAssets| Total owned assets|\n",
    "|TotalLiabilities| Total owed debts|\n",
    "|MonthlyIncome| Income per month|\n",
    "|UtilityBillsPaymentHistory| Utility payment record|\n",
    "|JobTenure| Job duration|\n",
    "|NetWorth| Total financial worth|\n",
    "|BaseInterestRate| Starting interest rate|\n",
    "|InterestRate| Applied interest rate|\n",
    "|MonthlyLoanPayment| Monthly loan payment|\n",
    "|TotalDebtToIncomeRatio| Total debt against income|\n",
    "|LoanApproved| Loan approval status|\n",
    "|RiskScore| Risk assessment score|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0VDQbC-es_8"
   },
   "source": [
    "## Task Description\n",
    "Your high level goal in this notebook is to build and evaluate predictive models for 'loan approval' from other available features. More specifically, you need to complete the following major tasks:\n",
    "\n",
    "1. Clean and preprocess the dataset for the downstream data analysis tasks.\n",
    "\n",
    "2. Build and evaluate logistic regression models with this datasets.\n",
    "\n",
    "3. Build and evaluate KNN models with this datasets.\n",
    "\n",
    "Note 1: While the main steps of each task have been given with the requirements, you should learn how to properly organise and comment your notebook by yourself to ensure that your notebook file is professional and readable.\n",
    "\n",
    "Note 2: You will be evaluated on the accuracy of the model, the process that you produce the results,  and your clear description and justification of your implementation. So, try your best to comment your source code to showing your understanding and critical thinking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset and show the basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicationDate</th>\n",
       "      <th>Age</th>\n",
       "      <th>AnnualIncome</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>EmploymentStatus</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Experience</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>LoanDuration</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>...</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>UtilityBillsPaymentHistory</th>\n",
       "      <th>JobTenure</th>\n",
       "      <th>NetWorth</th>\n",
       "      <th>BaseInterestRate</th>\n",
       "      <th>InterestRate</th>\n",
       "      <th>MonthlyLoanPayment</th>\n",
       "      <th>TotalDebtToIncomeRatio</th>\n",
       "      <th>LoanApproved</th>\n",
       "      <th>RiskScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>45.0</td>\n",
       "      <td>39948</td>\n",
       "      <td>617</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Master</td>\n",
       "      <td>22</td>\n",
       "      <td>13152</td>\n",
       "      <td>48</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>3329.000000</td>\n",
       "      <td>0.724972</td>\n",
       "      <td>11</td>\n",
       "      <td>126928</td>\n",
       "      <td>0.199652</td>\n",
       "      <td>0.227590</td>\n",
       "      <td>419.805992</td>\n",
       "      <td>0.181077</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39709</td>\n",
       "      <td>628</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Associate</td>\n",
       "      <td>15</td>\n",
       "      <td>26045</td>\n",
       "      <td>48</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>3309.083333</td>\n",
       "      <td>0.935132</td>\n",
       "      <td>3</td>\n",
       "      <td>43609</td>\n",
       "      <td>0.207045</td>\n",
       "      <td>0.201077</td>\n",
       "      <td>794.054238</td>\n",
       "      <td>0.389852</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>47.0</td>\n",
       "      <td>40724</td>\n",
       "      <td>570</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>26</td>\n",
       "      <td>17627</td>\n",
       "      <td>36</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>3393.666667</td>\n",
       "      <td>0.872241</td>\n",
       "      <td>6</td>\n",
       "      <td>5205</td>\n",
       "      <td>0.217627</td>\n",
       "      <td>0.212548</td>\n",
       "      <td>666.406688</td>\n",
       "      <td>0.462157</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>58.0</td>\n",
       "      <td>69084</td>\n",
       "      <td>545</td>\n",
       "      <td>Employed</td>\n",
       "      <td>High School</td>\n",
       "      <td>34</td>\n",
       "      <td>37898</td>\n",
       "      <td>96</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>5757.000000</td>\n",
       "      <td>0.896155</td>\n",
       "      <td>5</td>\n",
       "      <td>99452</td>\n",
       "      <td>0.300398</td>\n",
       "      <td>0.300911</td>\n",
       "      <td>1047.506980</td>\n",
       "      <td>0.313098</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>37.0</td>\n",
       "      <td>103264</td>\n",
       "      <td>594</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Associate</td>\n",
       "      <td>17</td>\n",
       "      <td>9184</td>\n",
       "      <td>36</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>8605.333333</td>\n",
       "      <td>0.941369</td>\n",
       "      <td>5</td>\n",
       "      <td>227019</td>\n",
       "      <td>0.197184</td>\n",
       "      <td>0.175990</td>\n",
       "      <td>330.179140</td>\n",
       "      <td>0.070210</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ApplicationDate   Age  AnnualIncome  CreditScore EmploymentStatus  \\\n",
       "0      2018-01-01  45.0         39948          617         Employed   \n",
       "1      2018-01-02  38.0         39709          628         Employed   \n",
       "2      2018-01-03  47.0         40724          570         Employed   \n",
       "3      2018-01-04  58.0         69084          545         Employed   \n",
       "4      2018-01-05  37.0        103264          594         Employed   \n",
       "\n",
       "  EducationLevel  Experience  LoanAmount  LoanDuration MaritalStatus  ...  \\\n",
       "0         Master          22       13152            48       Married  ...   \n",
       "1      Associate          15       26045            48        Single  ...   \n",
       "2       Bachelor          26       17627            36       Married  ...   \n",
       "3    High School          34       37898            96        Single  ...   \n",
       "4      Associate          17        9184            36       Married  ...   \n",
       "\n",
       "   MonthlyIncome UtilityBillsPaymentHistory  JobTenure  NetWorth  \\\n",
       "0    3329.000000                   0.724972         11    126928   \n",
       "1    3309.083333                   0.935132          3     43609   \n",
       "2    3393.666667                   0.872241          6      5205   \n",
       "3    5757.000000                   0.896155          5     99452   \n",
       "4    8605.333333                   0.941369          5    227019   \n",
       "\n",
       "   BaseInterestRate  InterestRate  MonthlyLoanPayment  TotalDebtToIncomeRatio  \\\n",
       "0          0.199652      0.227590          419.805992                0.181077   \n",
       "1          0.207045      0.201077          794.054238                0.389852   \n",
       "2          0.217627      0.212548          666.406688                0.462157   \n",
       "3          0.300398      0.300911         1047.506980                0.313098   \n",
       "4          0.197184      0.175990          330.179140                0.070210   \n",
       "\n",
       "  LoanApproved  RiskScore  \n",
       "0            0        NaN  \n",
       "1            0       52.0  \n",
       "2            0        NaN  \n",
       "3            0        NaN  \n",
       "4            1        NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('loan_approval.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 36 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   ApplicationDate             20000 non-null  object \n",
      " 1   Age                         19900 non-null  float64\n",
      " 2   AnnualIncome                20000 non-null  int64  \n",
      " 3   CreditScore                 20000 non-null  int64  \n",
      " 4   EmploymentStatus            20000 non-null  object \n",
      " 5   EducationLevel              20000 non-null  object \n",
      " 6   Experience                  20000 non-null  int64  \n",
      " 7   LoanAmount                  20000 non-null  int64  \n",
      " 8   LoanDuration                20000 non-null  int64  \n",
      " 9   MaritalStatus               19900 non-null  object \n",
      " 10  NumberOfDependents          20000 non-null  int64  \n",
      " 11  HomeOwnershipStatus         20000 non-null  object \n",
      " 12  MonthlyDebtPayments         20000 non-null  int64  \n",
      " 13  CreditCardUtilizationRate   20000 non-null  float64\n",
      " 14  NumberOfOpenCreditLines     20000 non-null  int64  \n",
      " 15  NumberOfCreditInquiries     20000 non-null  int64  \n",
      " 16  DebtToIncomeRatio           20000 non-null  float64\n",
      " 17  BankruptcyHistory           20000 non-null  int64  \n",
      " 18  LoanPurpose                 20000 non-null  object \n",
      " 19  PreviousLoanDefaults        20000 non-null  int64  \n",
      " 20  PaymentHistory              20000 non-null  int64  \n",
      " 21  LengthOfCreditHistory       20000 non-null  int64  \n",
      " 22  SavingsAccountBalance       20000 non-null  int64  \n",
      " 23  CheckingAccountBalance      20000 non-null  int64  \n",
      " 24  TotalAssets                 20000 non-null  int64  \n",
      " 25  TotalLiabilities            20000 non-null  int64  \n",
      " 26  MonthlyIncome               20000 non-null  float64\n",
      " 27  UtilityBillsPaymentHistory  20000 non-null  float64\n",
      " 28  JobTenure                   20000 non-null  int64  \n",
      " 29  NetWorth                    20000 non-null  int64  \n",
      " 30  BaseInterestRate            20000 non-null  float64\n",
      " 31  InterestRate                20000 non-null  float64\n",
      " 32  MonthlyLoanPayment          20000 non-null  float64\n",
      " 33  TotalDebtToIncomeRatio      20000 non-null  float64\n",
      " 34  LoanApproved                20000 non-null  int64  \n",
      " 35  RiskScore                   1000 non-null   float64\n",
      "dtypes: float64(10), int64(20), object(6)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicationDate</th>\n",
       "      <th>Age</th>\n",
       "      <th>AnnualIncome</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>EmploymentStatus</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Experience</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>LoanDuration</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>...</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>UtilityBillsPaymentHistory</th>\n",
       "      <th>JobTenure</th>\n",
       "      <th>NetWorth</th>\n",
       "      <th>BaseInterestRate</th>\n",
       "      <th>InterestRate</th>\n",
       "      <th>MonthlyLoanPayment</th>\n",
       "      <th>TotalDebtToIncomeRatio</th>\n",
       "      <th>LoanApproved</th>\n",
       "      <th>RiskScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000</td>\n",
       "      <td>19900.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>19900</td>\n",
       "      <td>...</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>2.000000e+04</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>20000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2072-09-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17036</td>\n",
       "      <td>6054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9999</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>39.751759</td>\n",
       "      <td>59161.473550</td>\n",
       "      <td>571.612400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.522750</td>\n",
       "      <td>24882.867800</td>\n",
       "      <td>54.057000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4891.715521</td>\n",
       "      <td>0.799918</td>\n",
       "      <td>5.002650</td>\n",
       "      <td>7.229432e+04</td>\n",
       "      <td>0.239124</td>\n",
       "      <td>0.239110</td>\n",
       "      <td>911.607052</td>\n",
       "      <td>0.402182</td>\n",
       "      <td>0.239000</td>\n",
       "      <td>50.687600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11.630809</td>\n",
       "      <td>40350.845168</td>\n",
       "      <td>50.997358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.316836</td>\n",
       "      <td>13427.421217</td>\n",
       "      <td>24.664857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3296.771598</td>\n",
       "      <td>0.120665</td>\n",
       "      <td>2.236804</td>\n",
       "      <td>1.179200e+05</td>\n",
       "      <td>0.035509</td>\n",
       "      <td>0.042205</td>\n",
       "      <td>674.583473</td>\n",
       "      <td>0.338924</td>\n",
       "      <td>0.426483</td>\n",
       "      <td>7.881033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>343.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3674.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>0.259203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>0.130101</td>\n",
       "      <td>0.113310</td>\n",
       "      <td>97.030193</td>\n",
       "      <td>0.016043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>31679.000000</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>15575.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2629.583333</td>\n",
       "      <td>0.727379</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.734750e+03</td>\n",
       "      <td>0.213889</td>\n",
       "      <td>0.209142</td>\n",
       "      <td>493.763700</td>\n",
       "      <td>0.179693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>48566.000000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>21914.500000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4034.750000</td>\n",
       "      <td>0.820962</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.285550e+04</td>\n",
       "      <td>0.236157</td>\n",
       "      <td>0.235390</td>\n",
       "      <td>728.511452</td>\n",
       "      <td>0.302711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>74391.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>30835.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6163.000000</td>\n",
       "      <td>0.892333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.882550e+04</td>\n",
       "      <td>0.261533</td>\n",
       "      <td>0.265532</td>\n",
       "      <td>1112.770759</td>\n",
       "      <td>0.509214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>485341.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>184732.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>0.999433</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.603208e+06</td>\n",
       "      <td>0.405029</td>\n",
       "      <td>0.446787</td>\n",
       "      <td>10892.629520</td>\n",
       "      <td>4.647657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>77.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ApplicationDate           Age   AnnualIncome   CreditScore  \\\n",
       "count            20000  19900.000000   20000.000000  20000.000000   \n",
       "unique           20000           NaN            NaN           NaN   \n",
       "top         2072-09-17           NaN            NaN           NaN   \n",
       "freq                 1           NaN            NaN           NaN   \n",
       "mean               NaN     39.751759   59161.473550    571.612400   \n",
       "std                NaN     11.630809   40350.845168     50.997358   \n",
       "min                NaN     18.000000   15000.000000    343.000000   \n",
       "25%                NaN     31.750000   31679.000000    540.000000   \n",
       "50%                NaN     40.000000   48566.000000    578.000000   \n",
       "75%                NaN     48.000000   74391.000000    609.000000   \n",
       "max                NaN     80.000000  485341.000000    712.000000   \n",
       "\n",
       "       EmploymentStatus EducationLevel    Experience     LoanAmount  \\\n",
       "count             20000          20000  20000.000000   20000.000000   \n",
       "unique                3              5           NaN            NaN   \n",
       "top            Employed       Bachelor           NaN            NaN   \n",
       "freq              17036           6054           NaN            NaN   \n",
       "mean                NaN            NaN     17.522750   24882.867800   \n",
       "std                 NaN            NaN     11.316836   13427.421217   \n",
       "min                 NaN            NaN      0.000000    3674.000000   \n",
       "25%                 NaN            NaN      9.000000   15575.000000   \n",
       "50%                 NaN            NaN     17.000000   21914.500000   \n",
       "75%                 NaN            NaN     25.000000   30835.000000   \n",
       "max                 NaN            NaN     61.000000  184732.000000   \n",
       "\n",
       "        LoanDuration MaritalStatus  ...  MonthlyIncome  \\\n",
       "count   20000.000000         19900  ...   20000.000000   \n",
       "unique           NaN             4  ...            NaN   \n",
       "top              NaN       Married  ...            NaN   \n",
       "freq             NaN          9999  ...            NaN   \n",
       "mean       54.057000           NaN  ...    4891.715521   \n",
       "std        24.664857           NaN  ...    3296.771598   \n",
       "min        12.000000           NaN  ...    1250.000000   \n",
       "25%        36.000000           NaN  ...    2629.583333   \n",
       "50%        48.000000           NaN  ...    4034.750000   \n",
       "75%        72.000000           NaN  ...    6163.000000   \n",
       "max       120.000000           NaN  ...   25000.000000   \n",
       "\n",
       "       UtilityBillsPaymentHistory     JobTenure      NetWorth  \\\n",
       "count                20000.000000  20000.000000  2.000000e+04   \n",
       "unique                        NaN           NaN           NaN   \n",
       "top                           NaN           NaN           NaN   \n",
       "freq                          NaN           NaN           NaN   \n",
       "mean                     0.799918      5.002650  7.229432e+04   \n",
       "std                      0.120665      2.236804  1.179200e+05   \n",
       "min                      0.259203      0.000000  1.000000e+03   \n",
       "25%                      0.727379      3.000000  8.734750e+03   \n",
       "50%                      0.820962      5.000000  3.285550e+04   \n",
       "75%                      0.892333      6.000000  8.882550e+04   \n",
       "max                      0.999433     16.000000  2.603208e+06   \n",
       "\n",
       "        BaseInterestRate  InterestRate  MonthlyLoanPayment  \\\n",
       "count       20000.000000  20000.000000        20000.000000   \n",
       "unique               NaN           NaN                 NaN   \n",
       "top                  NaN           NaN                 NaN   \n",
       "freq                 NaN           NaN                 NaN   \n",
       "mean            0.239124      0.239110          911.607052   \n",
       "std             0.035509      0.042205          674.583473   \n",
       "min             0.130101      0.113310           97.030193   \n",
       "25%             0.213889      0.209142          493.763700   \n",
       "50%             0.236157      0.235390          728.511452   \n",
       "75%             0.261533      0.265532         1112.770759   \n",
       "max             0.405029      0.446787        10892.629520   \n",
       "\n",
       "        TotalDebtToIncomeRatio  LoanApproved    RiskScore  \n",
       "count             20000.000000  20000.000000  1000.000000  \n",
       "unique                     NaN           NaN          NaN  \n",
       "top                        NaN           NaN          NaN  \n",
       "freq                       NaN           NaN          NaN  \n",
       "mean                  0.402182      0.239000    50.687600  \n",
       "std                   0.338924      0.426483     7.881033  \n",
       "min                   0.016043      0.000000    30.400000  \n",
       "25%                   0.179693      0.000000    46.000000  \n",
       "50%                   0.302711      0.000000    52.000000  \n",
       "75%                   0.509214      0.000000    56.000000  \n",
       "max                   4.647657      1.000000    77.000000  \n",
       "\n",
       "[11 rows x 36 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Clean the datasets (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.1 Handle the missing values with follwoing rules (5 marks)\n",
    "1. If over 50% of the values of a column, the column should be removed from the data frame; \n",
    "2. For a categorical column, if a row contains a missing value, you need to delete the whole row; \n",
    "3. For a numerical column, if a row contains a missing value, you need to perform a missing value imputation with the average value of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19900 entries, 0 to 19999\n",
      "Data columns (total 35 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   ApplicationDate             19900 non-null  object \n",
      " 1   Age                         19900 non-null  float64\n",
      " 2   AnnualIncome                19900 non-null  int64  \n",
      " 3   CreditScore                 19900 non-null  int64  \n",
      " 4   EmploymentStatus            19900 non-null  object \n",
      " 5   EducationLevel              19900 non-null  object \n",
      " 6   Experience                  19900 non-null  int64  \n",
      " 7   LoanAmount                  19900 non-null  int64  \n",
      " 8   LoanDuration                19900 non-null  int64  \n",
      " 9   MaritalStatus               19900 non-null  object \n",
      " 10  NumberOfDependents          19900 non-null  int64  \n",
      " 11  HomeOwnershipStatus         19900 non-null  object \n",
      " 12  MonthlyDebtPayments         19900 non-null  int64  \n",
      " 13  CreditCardUtilizationRate   19900 non-null  float64\n",
      " 14  NumberOfOpenCreditLines     19900 non-null  int64  \n",
      " 15  NumberOfCreditInquiries     19900 non-null  int64  \n",
      " 16  DebtToIncomeRatio           19900 non-null  float64\n",
      " 17  BankruptcyHistory           19900 non-null  int64  \n",
      " 18  LoanPurpose                 19900 non-null  object \n",
      " 19  PreviousLoanDefaults        19900 non-null  int64  \n",
      " 20  PaymentHistory              19900 non-null  int64  \n",
      " 21  LengthOfCreditHistory       19900 non-null  int64  \n",
      " 22  SavingsAccountBalance       19900 non-null  int64  \n",
      " 23  CheckingAccountBalance      19900 non-null  int64  \n",
      " 24  TotalAssets                 19900 non-null  int64  \n",
      " 25  TotalLiabilities            19900 non-null  int64  \n",
      " 26  MonthlyIncome               19900 non-null  float64\n",
      " 27  UtilityBillsPaymentHistory  19900 non-null  float64\n",
      " 28  JobTenure                   19900 non-null  int64  \n",
      " 29  NetWorth                    19900 non-null  int64  \n",
      " 30  BaseInterestRate            19900 non-null  float64\n",
      " 31  InterestRate                19900 non-null  float64\n",
      " 32  MonthlyLoanPayment          19900 non-null  float64\n",
      " 33  TotalDebtToIncomeRatio      19900 non-null  float64\n",
      " 34  LoanApproved                19900 non-null  int64  \n",
      "dtypes: float64(9), int64(20), object(6)\n",
      "memory usage: 5.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# remove columns with > 50% missing values\n",
    "columns_to_drop = data.columns[data.isnull().mean() > 0.5] # check which colums have over 50% missing values\n",
    "data = data.drop(columns_to_drop, axis=1) #drop the colums found from the dataset\n",
    "\n",
    "# remove rows with missing values\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns #find categorical columns\n",
    "data = data.dropna(subset=categorical_cols) #drop rows with missing values\n",
    "\n",
    "# replace null values with an average for numerical columns\n",
    "numeric_cols = data.select_dtypes(include=['float', 'int']).columns #find numerical columns\n",
    "for col in numeric_cols:\n",
    "    data[col] = data[col].fillna(data[col].mean()) # replacing null values with averages\n",
    "\n",
    "# print cleaned dataset\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.2 Handle categorical attributes (5 marks)\n",
    "1. If all the categorical values of a column are unique, this column does not provide any statistical informaiton and should be deleted.\n",
    "2. Use one hot encoding to convert the categorical values into numerical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 36 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   ApplicationDate             20000 non-null  object \n",
      " 1   Age                         19900 non-null  float64\n",
      " 2   AnnualIncome                20000 non-null  int64  \n",
      " 3   CreditScore                 20000 non-null  int64  \n",
      " 4   EmploymentStatus            20000 non-null  object \n",
      " 5   EducationLevel              20000 non-null  object \n",
      " 6   Experience                  20000 non-null  int64  \n",
      " 7   LoanAmount                  20000 non-null  int64  \n",
      " 8   LoanDuration                20000 non-null  int64  \n",
      " 9   MaritalStatus               19900 non-null  object \n",
      " 10  NumberOfDependents          20000 non-null  int64  \n",
      " 11  HomeOwnershipStatus         20000 non-null  object \n",
      " 12  MonthlyDebtPayments         20000 non-null  int64  \n",
      " 13  CreditCardUtilizationRate   20000 non-null  float64\n",
      " 14  NumberOfOpenCreditLines     20000 non-null  int64  \n",
      " 15  NumberOfCreditInquiries     20000 non-null  int64  \n",
      " 16  DebtToIncomeRatio           20000 non-null  float64\n",
      " 17  BankruptcyHistory           20000 non-null  int64  \n",
      " 18  LoanPurpose                 20000 non-null  object \n",
      " 19  PreviousLoanDefaults        20000 non-null  int64  \n",
      " 20  PaymentHistory              20000 non-null  int64  \n",
      " 21  LengthOfCreditHistory       20000 non-null  int64  \n",
      " 22  SavingsAccountBalance       20000 non-null  int64  \n",
      " 23  CheckingAccountBalance      20000 non-null  int64  \n",
      " 24  TotalAssets                 20000 non-null  int64  \n",
      " 25  TotalLiabilities            20000 non-null  int64  \n",
      " 26  MonthlyIncome               20000 non-null  float64\n",
      " 27  UtilityBillsPaymentHistory  20000 non-null  float64\n",
      " 28  JobTenure                   20000 non-null  int64  \n",
      " 29  NetWorth                    20000 non-null  int64  \n",
      " 30  BaseInterestRate            20000 non-null  float64\n",
      " 31  InterestRate                20000 non-null  float64\n",
      " 32  MonthlyLoanPayment          20000 non-null  float64\n",
      " 33  TotalDebtToIncomeRatio      20000 non-null  float64\n",
      " 34  LoanApproved                20000 non-null  int64  \n",
      " 35  RiskScore                   1000 non-null   float64\n",
      "dtypes: float64(10), int64(20), object(6)\n",
      "memory usage: 5.5+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Columns: 20050 entries, Age to LoanPurpose_Other\n",
      "dtypes: bool(20021), float64(9), int64(20)\n",
      "memory usage: 386.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('loan_approval.csv') # load dataset\n",
    "\n",
    "data.head() \n",
    "data.info()\n",
    "data.describe(include='all')\n",
    "\n",
    "# 1. remove the columns without statistical information\n",
    "columns_to_drop = data.columns[data.isnull().mean() >0.5] # couldnt use isunique with numbers so tried isnull and used 50% \n",
    "data = data.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# 2. covert values to numerical values\n",
    "data = pd.get_dummies(data, columns=data.select_dtypes(include=['object']).columns)\n",
    "\n",
    "print(data.info()) #print dataset information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Build a logistic regression classification model (25 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1 Specify the features and the label, and split the dataset into training data and testing data (5 marks)\n",
    "1. The attirbute \"LoanApproved\" is the label, which is the prediction target. The remaining attributes are the features.\n",
    "2. The ratio for splitting the dataset is 80% for training and 20% for testing. Note that you need to set the \"random_state\" parameter as your student ID to produce your personlised splitting. Failing to do so will lose marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X trtaing shape:  (16000, 20049)\n",
      "X testing shape:  (4000, 20049)\n",
      "Y training shape:  (16000,)\n",
      "Y testing shape:  (4000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = data.drop('LoanApproved', axis=1) \n",
    "y = data['LoanApproved']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=47690844)\n",
    "\n",
    "print(\"X trtaing shape: \", x_train.shape)\n",
    "print(\"X testing shape: \", x_test.shape)\n",
    "print(\"Y training shape: \", y_train.shape)\n",
    "print(\"Y testing shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2 Build a logistic regression model (10 marks)\n",
    "1. Train a logistic regression model\n",
    "2. Report two classification performance metrics (accuracy and f1-score) on the testing data\n",
    "3. Also report the two metrics on the training data, and compare the results with that of the testing data. Make a justification on whether the model is overfitting based on the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=47690844)\n",
    "\n",
    "# Handling missing numbers causing arrors\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "x_train = imputer.fit_transform(x_train)\n",
    "x_test = imputer.transform(x_test)\n",
    "\n",
    "# Initialize and train the modle\n",
    "log_reg = LogisticRegression(max_iter=500, random_state=47690844)\n",
    "log_reg.fit(x_train, y_train)\n",
    "\n",
    "# Report the accuracy and f1-score of the test data\n",
    "y_train_pred = log_reg.predict(x_train)\n",
    "test_accuracy = accuracy_score(y_test, y_train_pred)\n",
    "test_f1 = f1_score(y_test, y_train_pred)\n",
    "\n",
    "print(\"Test Accuracy : \", test_accuracy, \"/n\", \"F1-Score :\", test_f1)\n",
    "\n",
    "# Report 2 more metrix and compare data with the test data\n",
    "y_pred_train = log_reg.predict(x_train)\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "train_f1 = f1_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"/n\", \"Train Accuracy : \", train_accuracy, \"/n\", \"F1-Score :\", train_f1)\n",
    "\n",
    "# Justify the model by comparison \n",
    "if train_accuracy > test_accuracy:\n",
    "    print(\"The model is overfitting\")\n",
    "else:\n",
    "    print(\"The model is a good fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.3 Perform the recursive feature elimination (RFE) technique to identify the effective features for building the model (10 marks)\n",
    "1. Visulise the change of the two performance metrics with respect to the number of eliminated features using a line chart.\n",
    "2. In terms of the visualisation result, select a good value for the number of eliminated features with considering both performance maximisation and feature minimisation (two competing goals). Run the RFE again with the chosen number of eliminated features to obtain the corresponding set of retained features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m log_reg \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m47690844\u001b[39m)\n\u001b[0;32m     14\u001b[0m rfe \u001b[38;5;241m=\u001b[39m RFE(log_reg, n_features_to_select\u001b[38;5;241m=\u001b[39mnum_features_to_select)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mrfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m rfe\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     17\u001b[0m accuracy_scores\u001b[38;5;241m.\u001b[39mappend(accuracy_score(y_test, y_pred_test))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\feature_selection\\_rfe.py:268\u001b[0m, in \u001b[0;36mRFE.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the RFE model and then the underlying estimator on the selected features.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    267\u001b[0m _raise_for_unsupported_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\feature_selection\\_rfe.py:323\u001b[0m, in \u001b[0;36mRFE._fit\u001b[1;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting estimator with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m features.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m np\u001b[38;5;241m.\u001b[39msum(support_))\n\u001b[1;32m--> 323\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# Get importance and rank them\u001b[39;00m\n\u001b[0;32m    326\u001b[0m importances \u001b[38;5;241m=\u001b[39m _get_feature_importances(\n\u001b[0;32m    327\u001b[0m     estimator,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_getter,\n\u001b[0;32m    329\u001b[0m     transform_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquare\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    330\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1223\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1221\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1223\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1231\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[1;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "x = data.drop('LoanApproved', axis=1) \n",
    "y = data['LoanApproved']  \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=47690844)\n",
    "\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for num_features_to_select in range(1, x_train.shape[1] + 1):\n",
    "    log_reg = LogisticRegression(max_iter=1000, random_state=47690844)\n",
    "    rfe = RFE(log_reg, n_features_to_select=num_features_to_select)\n",
    "    rfe.fit(x_train, y_train)\n",
    "    y_pred_test = rfe.predict(x_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred_test))\n",
    "    f1_scores.append(f1_score(y_test, y_pred_test))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, x_train.shape[1] + 1), accuracy_scores, label='Accuracy Score', marker='o')\n",
    "plt.plot(range(1, x_train.shape[1] + 1), f1_scores, label='F1 Score', marker='x')\n",
    "plt.xlabel('Number of Features Selected')\n",
    "plt.ylabel('Performance Metrics')\n",
    "plt.title('Performance Metrics vs Number of Features Selected using RFE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "optimal_features = 15\n",
    "\n",
    "# Rerun RFE with the selected number of features\n",
    "log_reg_optimal = LogisticRegression(max_iter=1000, random_state=47690844)\n",
    "rfe_optimal = RFE(log_reg_optimal, n_features_to_select=optimal_features)\n",
    "rfe_optimal.fit(x_train, y_train)\n",
    "\n",
    "# retained feature names\n",
    "retained_features = x_train.columns[rfe_optimal.support_]\n",
    "print(f\"The optimal number of features is: {optimal_features}\")\n",
    "print(f\"The retained features are: {list(retained_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Build a KNN classification model (25 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1 Build 1-NN classifier (5 marks)\n",
    "1. Slect the features identifed in Step 2.3 for this task\n",
    "2. Buid 1-NN classifier and report two classification performance metrics (accuracy and f1-score) on the testing data\n",
    "3. Also report the two metrics on the training data, and compare the results with that of the testing data. Make a justification on whether the model is overfitting based on the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_selected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and testing data \u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mX_selected\u001b[49m, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m47690844\u001b[39m)\n\u001b[0;32m     11\u001b[0m knn_classifier \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Train the 1-NN classifier \u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_selected' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing data \n",
    "x_train, x_test, y_train, y_test = train_test_split(x_test, y, test_size=0.2, random_state=47690844)\n",
    "\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# Train the 1-NN classifier \n",
    "knn_classifier.fit(x_train, y_train)\n",
    "y_test_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and F1-score \n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Test Accuracy (1-NN): \", test_accuracy)\n",
    "print(\"F1-Score (Test) (1-NN):\", test_f1)\n",
    "\n",
    "# Predict and calculate performance metrics for the training data\n",
    "y_train_pred = knn_classifier.predict(x_train)\n",
    "\n",
    "# Calculate accuracy and F1-score \n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"\\nTrain Accuracy (1-NN): \", train_accuracy)\n",
    "print(\"F1-Score (Train) (1-NN):\", train_f1)\n",
    "\n",
    "# Justify the model by comparing training and testing results\n",
    "if train_accuracy > test_accuracy:\n",
    "    print(\"\\nThe model is overfitting (1-NN)\")\n",
    "else:\n",
    "    print(\"\\nThe model is a good fit (1-NN)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2 Use the grid search and cross validation techniques to study the performance change with respect to the hyperparameter K (10 marks)\n",
    "1. User grid search to search K in the range (1, 30) both inclusive with 5-fold cross validation. The performance metric used for search is accuracy.\n",
    "2. Visualise the performance change with respect to K using a line chart. Report the two performance metrics for the best case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4000, 20000]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, f1_score\n\u001b[1;32m----> 5\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m47690844\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNeighborsClassifier()\n\u001b[0;32m      8\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_neighbors\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m31\u001b[39m)}\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:2777\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2775\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2777\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2779\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2780\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2781\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2782\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <3x1 sparse matrix ...>]\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 514\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4000, 20000]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_test, y, test_size=0.2, random_state=47690844)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': np.arange(1, 31)}\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(f\"Best K: {best_k}\")\n",
    "print(f\"Best Accuracy (CV): {best_accuracy}\")\n",
    "\n",
    "# Train the classifier with the best K\n",
    "best_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "best_knn.fit(x_train, y_train)\n",
    "\n",
    "y_test_pred = best_knn.predict(x_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Accuracy (Best K): {test_accuracy}\")\n",
    "print(f\"F1-Score (Test) (Best K): {test_f1}\")\n",
    "\n",
    "# Visualize the performance using a line chart\n",
    "results = grid_search.cv_results_\n",
    "mean_test_scores = results['mean_test_score']\n",
    "k_values = np.arange(1, 31)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, mean_test_scores, marker='o')\n",
    "plt.title('Performance Change with Respect to K (Grid Search with 5-Fold Cross Validation)')\n",
    "plt.xlabel('Number of Neighbors (K)')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.3 Study how the distance metrics affect the model performance (10 marks)\n",
    "1. Change the distance metric parameter to 3 distance types: 'euclidean'(also l2), 'l1', and 'cosine', respectively, and visualise the model performance with these 3 distances, using a bar chart for both accuracy and f1 scores.\n",
    "2. Compare the performance metrics, which is the best? Which is the worest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nKNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m distance_metrics:\n\u001b[0;32m      7\u001b[0m     knn \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, metric\u001b[38;5;241m=\u001b[39mmetric)\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     y_test_pred \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     10\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_test_pred)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_classification.py:238\u001b[0m, in \u001b[0;36mKNeighborsClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# KNeighborsClassifier.metric is not validated yet\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    219\u001b[0m )\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m    221\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the k-nearest neighbors classifier from the training dataset.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m        The fitted k-nearest neighbors classifier.\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\neighbors\\_base.py:475\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[1;32m--> 475\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;66;03m# Classification targets require a specific format\u001b[39;00m\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[1;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nKNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# distance metrics\n",
    "distance_metrics = ['euclidean', 'manhattan', 'cosine']\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for metric in distance_metrics:\n",
    "    knn = KNeighborsClassifier(n_neighbors=1, metric=metric)\n",
    "    knn.fit(x_train, y_train)\n",
    "    y_test_pred = knn.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    f1 = f1_score(y_test, y_test_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    # Print the results for each metric\n",
    "    print(f\"Metric: {metric}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1-Score: {f1}\\n\")\n",
    "\n",
    "# Visualize the performance using a bar chart\n",
    "x = range(len(distance_metrics)) \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x, accuracy_scores, width=0.3, label='Accuracy', align='center')\n",
    "plt.bar([i + 0.3 for i in x], f1_scores, width=0.3, label='F1-Score', align='center')\n",
    "plt.xticks([i + 0.15 for i in x], distance_metrics)\n",
    "plt.xlabel('Distance Metric')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Comparison of Accuracy and F1-Score for Different Distance Metrics')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Compare the performance metrics\n",
    "best_accuracy_index = accuracy_scores.index(max(accuracy_scores))\n",
    "worst_accuracy_index = accuracy_scores.index(min(accuracy_scores))\n",
    "\n",
    "best_f1_index = f1_scores.index(max(f1_scores))\n",
    "worst_f1_index = f1_scores.index(min(f1_scores))\n",
    "\n",
    "print(f\"\\nBest Distance Metric for Accuracy: {distance_metrics[best_accuracy_index]} with score {max(accuracy_scores)}\")\n",
    "print(f\"Worst Distance Metric for Accuracy: {distance_metrics[worst_accuracy_index]} with score {min(accuracy_scores)}\")\n",
    "\n",
    "print(f\"Best Distance Metric for F1-Score: {distance_metrics[best_f1_index]} with score {max(f1_scores)}\")\n",
    "print(f\"Worst Distance Metric for F1-Score: {distance_metrics[worst_f1_index]} with score {min(f1_scores)}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
